{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "51bCCNa6r9Gt"
   },
   "source": [
    "**Instructions**\n",
    "\n",
    "1. Follow the instructions in each of the cell\n",
    "\n",
    "2. Make sure not to delete any of the cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dyx4dTC0r9HD"
   },
   "source": [
    "### Input Data\n",
    "\n",
    "Note : Dataset is in the input directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data\n",
    "df = pd.read_csv('input/DataSet_For_Cleaning.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fOwHz5O9tKeZ"
   },
   "source": [
    "**Q1. Return the Number of \"Duplicate Rows\" in the Given DataSet as an Integer**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z2ymSqkvtWeh",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "duplicated_rows = df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign your answer to this variable.\n",
    "q1=duplicated_rows.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop only the Duplicate rows in the original Dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated = df.drop(duplicated_rows.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8D4_K02wt4SF"
   },
   "source": [
    "**Q2.Return the Dimensions of the DataSet After Removing \"Duplicate Rows\"**\n",
    "\n",
    "Hint:Remove only the Duplicate rows not the Original Rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign your answer to this variable.\n",
    "q2= df_updated.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v5vro99HuvgM"
   },
   "source": [
    "*Something is Wrong With the Column \"Distance\"*\n",
    "\n",
    "**Check It Out !!!**\n",
    "\n",
    "Hint:Pre-process the column(replace ',' with '.' ) and convert it into \"Numeric\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_updated['Distance'] = df_updated['Distance'].apply(lambda x: x.replace(',','.'))\n",
    "df_updated['Distance'] = df_updated['Distance'].astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vfI0Kw6Xvj07"
   },
   "source": [
    "**Q3.Return the \"(Data)Type\" of the Column \"Distance\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign your answer to this variable.\n",
    "q3=df_updated.dtypes['Distance']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F5vto9i5wqln"
   },
   "source": [
    "*Check if there are any NULL values*\n",
    "\n",
    "**Deal With them \"EFFECTIVELY\" !!!**\n",
    "\n",
    "*Hint:* Replace **Numerical** NULL Values With their **Mean** & **Categorical** NULL Values With their **Mode** *Respectively*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2qRI5tVCxtsQ"
   },
   "source": [
    "**Q4.Return the Number of Non-Zero NULL Values Present in Each Columns in a Sorted LIST(Descending)**\n",
    "Hint:Only if NULL values are present in that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hln4_v2dwuEJ"
   },
   "outputs": [],
   "source": [
    "non_zero_vals = list(filter(lambda a: a != 0,df_updated.isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_vals.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Steps','Minutes_sitting','Minutes_of_slow_activity','Calories_Burned','Protein_Intake']\n",
    "df_updated = df_updated.fillna(df_updated.mean()[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign your answer to this variable.\n",
    "q4=non_zero_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OkbShXNA0DQx"
   },
   "source": [
    "**Q5.Return the Column \"Minutes_of_slow_activity\" as a LIST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign your answer to this variable.\n",
    "q5=list(df_updated['Minutes_of_slow_activity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G7gjWhcq0dU-"
   },
   "source": [
    "*A Lot is Wrong With the Column \"Protein_Source\"*\n",
    "\n",
    "Hint:\n",
    "\n",
    "Sources of Protein :\n",
    "\n",
    "'Chicken', 'Mutton', 'Soya', 'Cheese', 'Fish', 'Protein Suppliments', 'Eggs', 'Beef', 'Pulses', 'Protein Shake'\n",
    "\n",
    "*Look for spelling errors.\n",
    "\n",
    "*spellings are Case sensitive\n",
    "\n",
    "*Use the exact spelling as above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CBiyNYqD04GJ"
   },
   "source": [
    "**Q6.Return the Column \"Protein_Source\" as a LIST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dVDiJK1Z0vmN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Chicken', 'Mutton', 'Soya', 'Cheeeeeese', 'Fish',\n",
       "       'Protein Suppliments', 'Eggs', 'Beef', 'Pulses', 'Protein Shake',\n",
       "       'Chick', 'Chicken65', 'Muttttton', 'Cheese', 'Hen', 'Cheeeese',\n",
       "       'Cheeze', 'Freeze', 'hicken', 'Soy', 'Goat', 'Lamb', 'Mutt'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_updated['Protein_Source'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(x):\n",
    "    if x in ['Chicken','Chick','Chicken65','hicken','Hen']:\n",
    "        return 'Chicken'\n",
    "    elif x in ['Cheeeeeese','Cheeeese','Cheeze','Freeze']:\n",
    "        return 'Cheese'\n",
    "    elif x in ['Muttttton','Mutt','Goat', 'Lamb']:\n",
    "        return 'Mutton'\n",
    "    elif x in ['Soya']:\n",
    "        return 'Soy'\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lxnnpsyI0wq7"
   },
   "outputs": [],
   "source": [
    "df_updated['Protein_Source'] = df_updated['Protein_Source'].apply(lambda x: process(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Chicken', 'Mutton', 'Soy', 'Cheese', 'Fish',\n",
       "       'Protein Suppliments', 'Eggs', 'Beef', 'Pulses', 'Protein Shake'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_updated['Protein_Source'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign your answer to this variable.\n",
    "\n",
    "q6= list(df_updated['Protein_Source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chicken',\n",
       " 'Mutton',\n",
       " 'Soy',\n",
       " 'Cheese',\n",
       " 'Fish',\n",
       " 'Protein Suppliments',\n",
       " 'Eggs',\n",
       " 'Beef',\n",
       " 'Pulses',\n",
       " 'Protein Shake',\n",
       " 'Chicken',\n",
       " 'Mutton',\n",
       " 'Eggs',\n",
       " 'Mutton',\n",
       " 'Beef',\n",
       " 'Protein Suppliments',\n",
       " 'Pulses',\n",
       " 'Chicken',\n",
       " 'Protein Shake',\n",
       " 'Mutton',\n",
       " 'Chicken',\n",
       " 'Beef',\n",
       " 'Soy',\n",
       " 'Mutton',\n",
       " 'Pulses',\n",
       " 'Protein Suppliments',\n",
       " 'Soy',\n",
       " 'Protein Shake',\n",
       " 'Beef',\n",
       " 'Mutton',\n",
       " 'Chicken',\n",
       " 'Mutton',\n",
       " 'Pulses',\n",
       " 'Cheese',\n",
       " 'Soy',\n",
       " 'Beef',\n",
       " 'Protein Shake',\n",
       " 'Mutton',\n",
       " 'Soy',\n",
       " 'Cheese',\n",
       " 'Chicken',\n",
       " 'Mutton',\n",
       " 'Beef',\n",
       " 'Mutton',\n",
       " 'Fish',\n",
       " 'Protein Shake',\n",
       " 'Soy',\n",
       " 'Mutton',\n",
       " 'Pulses',\n",
       " 'Beef',\n",
       " 'Chicken',\n",
       " 'Cheese',\n",
       " 'Fish',\n",
       " 'Mutton',\n",
       " 'Protein Shake',\n",
       " 'Protein Suppliments',\n",
       " 'Pulses',\n",
       " 'Cheese',\n",
       " 'Soy',\n",
       " 'Mutton',\n",
       " 'Chicken',\n",
       " 'Mutton',\n",
       " 'Soy',\n",
       " 'Protein Shake',\n",
       " 'Pulses',\n",
       " 'Protein Suppliments',\n",
       " 'Eggs',\n",
       " 'Mutton',\n",
       " 'Fish',\n",
       " 'Cheese',\n",
       " 'Chicken',\n",
       " 'Mutton',\n",
       " 'Protein Shake',\n",
       " 'Mutton',\n",
       " 'Soy',\n",
       " 'Protein Suppliments',\n",
       " 'Fish',\n",
       " 'Beef',\n",
       " 'Eggs',\n",
       " 'Mutton',\n",
       " 'Chicken',\n",
       " 'Protein Shake',\n",
       " 'Soy',\n",
       " 'Mutton',\n",
       " 'Beef',\n",
       " 'Protein Suppliments',\n",
       " 'Soy',\n",
       " 'Cheese',\n",
       " 'Pulses',\n",
       " 'Mutton',\n",
       " 'Chicken',\n",
       " 'Beef',\n",
       " 'Fish',\n",
       " 'Cheese',\n",
       " 'Soy',\n",
       " 'Protein Suppliments',\n",
       " 'Pulses',\n",
       " 'Mutton',\n",
       " 'Beef',\n",
       " 'Protein Shake',\n",
       " 'Chicken',\n",
       " 'Mutton',\n",
       " 'Eggs',\n",
       " 'Mutton',\n",
       " 'Pulses',\n",
       " 'Beef',\n",
       " 'Soy',\n",
       " 'Mutton',\n",
       " 'Protein Shake',\n",
       " 'Mutton',\n",
       " 'Chicken',\n",
       " 'Cheese',\n",
       " 'Pulses',\n",
       " 'Mutton',\n",
       " 'Eggs',\n",
       " 'Protein Suppliments',\n",
       " 'Fish',\n",
       " 'Protein Shake',\n",
       " 'Soy',\n",
       " 'Beef',\n",
       " 'Chicken',\n",
       " 'Mutton',\n",
       " 'Soy',\n",
       " 'Cheese',\n",
       " 'Fish',\n",
       " 'Protein Suppliments',\n",
       " 'Protein Shake',\n",
       " 'Mutton',\n",
       " 'Pulses',\n",
       " 'Cheese',\n",
       " 'Chicken',\n",
       " 'Mutton',\n",
       " 'Eggs',\n",
       " 'Beef',\n",
       " 'Soy',\n",
       " 'Protein Shake',\n",
       " 'Pulses',\n",
       " 'Mutton',\n",
       " 'Eggs',\n",
       " 'Mutton',\n",
       " 'Chicken',\n",
       " 'Cheese',\n",
       " 'Soy',\n",
       " 'Mutton',\n",
       " 'Protein Shake',\n",
       " 'Protein Suppliments',\n",
       " 'Soy',\n",
       " 'Beef',\n",
       " 'Fish',\n",
       " 'Mutton',\n",
       " 'Chicken',\n",
       " 'Mutton',\n",
       " 'Pulses',\n",
       " 'Protein Shake',\n",
       " 'Beef',\n",
       " 'Protein Suppliments',\n",
       " 'Eggs',\n",
       " 'Mutton',\n",
       " 'Soy',\n",
       " 'Cheese',\n",
       " 'Chicken',\n",
       " 'Beef',\n",
       " 'Protein Shake',\n",
       " 'Mutton',\n",
       " 'Fish',\n",
       " 'Protein Suppliments',\n",
       " 'Soy',\n",
       " 'Mutton',\n",
       " 'Pulses',\n",
       " 'Mutton',\n",
       " 'Chicken',\n",
       " 'Protein Shake',\n",
       " 'Fish',\n",
       " 'Mutton',\n",
       " 'Eggs',\n",
       " 'Beef',\n",
       " 'Pulses',\n",
       " 'Cheese',\n",
       " 'Soy',\n",
       " 'Mutton',\n",
       " 'Chicken',\n",
       " 'Mutton',\n",
       " 'Beef',\n",
       " 'Cheese',\n",
       " 'Pulses',\n",
       " 'Protein Suppliments',\n",
       " 'Eggs',\n",
       " 'Mutton',\n",
       " 'Fish',\n",
       " 'Protein Shake',\n",
       " 'Chicken',\n",
       " 'Mutton',\n",
       " 'Pulses',\n",
       " 'Mutton',\n",
       " 'Soy',\n",
       " 'Protein Suppliments',\n",
       " 'Beef',\n",
       " 'Mutton',\n",
       " 'Protein Shake',\n",
       " 'Mutton',\n",
       " 'Chicken',\n",
       " 'Cheese',\n",
       " 'Soy',\n",
       " 'Beef',\n",
       " 'Eggs',\n",
       " 'Protein Suppliments',\n",
       " 'Soy',\n",
       " 'Protein Shake',\n",
       " 'Pulses',\n",
       " 'Mutton',\n",
       " 'Chicken',\n",
       " 'Mutton',\n",
       " 'Fish',\n",
       " 'Cheese',\n",
       " 'Soy',\n",
       " 'Protein Suppliments',\n",
       " 'Protein Shake',\n",
       " 'Beef',\n",
       " 'Soy',\n",
       " 'Cheese',\n",
       " 'Chicken',\n",
       " 'Mutton',\n",
       " 'Eggs',\n",
       " 'Mutton',\n",
       " 'Pulses',\n",
       " 'Protein Shake',\n",
       " 'Soy',\n",
       " 'Mutton',\n",
       " 'Eggs',\n",
       " 'Mutton',\n",
       " 'Chicken',\n",
       " 'Beef',\n",
       " 'Pulses',\n",
       " 'Mutton',\n",
       " 'Protein Shake',\n",
       " 'Protein Suppliments',\n",
       " 'Fish',\n",
       " 'Cheese',\n",
       " 'Beef',\n",
       " 'Mutton',\n",
       " 'Chicken',\n",
       " 'Mutton',\n",
       " 'Soy',\n",
       " 'Protein Shake',\n",
       " 'Fish',\n",
       " 'Beef',\n",
       " 'Eggs',\n",
       " 'Mutton',\n",
       " 'Pulses',\n",
       " 'Cheese',\n",
       " 'Chicken',\n",
       " 'Mutton',\n",
       " 'Protein Shake',\n",
       " 'Mutton',\n",
       " 'Soy',\n",
       " 'Protein Suppliments',\n",
       " 'Pulses',\n",
       " 'Mutton',\n",
       " 'Eggs',\n",
       " 'Beef',\n",
       " 'Chicken',\n",
       " 'Protein Shake',\n",
       " 'Soy',\n",
       " 'Mutton',\n",
       " 'Pulses',\n",
       " 'Protein Suppliments',\n",
       " 'Beef',\n",
       " 'Cheese',\n",
       " 'Fish',\n",
       " 'Mutton',\n",
       " 'Chicken',\n",
       " 'Mutton',\n",
       " 'Pulses',\n",
       " 'Beef',\n",
       " 'Soy',\n",
       " 'Protein Suppliments',\n",
       " 'Eggs',\n",
       " 'Mutton',\n",
       " 'Soy',\n",
       " 'Protein Shake',\n",
       " 'Chicken',\n",
       " 'Mutton',\n",
       " 'Eggs',\n",
       " 'Mutton',\n",
       " 'Fish',\n",
       " 'Protein Suppliments',\n",
       " 'Soy',\n",
       " 'Beef',\n",
       " 'Protein Shake',\n",
       " 'Mutton',\n",
       " 'Chicken',\n",
       " 'Cheese',\n",
       " 'Fish',\n",
       " 'Mutton',\n",
       " 'Beef',\n",
       " 'Protein Suppliments',\n",
       " 'Pulses',\n",
       " 'Protein Shake',\n",
       " 'Soy',\n",
       " 'Mutton',\n",
       " 'Chicken',\n",
       " 'Beef',\n",
       " 'Soy',\n",
       " 'Cheese',\n",
       " 'Pulses',\n",
       " 'Protein Suppliments',\n",
       " 'Protein Shake',\n",
       " 'Mutton',\n",
       " 'Beef',\n",
       " 'Cheese',\n",
       " 'Chicken',\n",
       " 'Mutton',\n",
       " 'Pulses',\n",
       " 'Mutton',\n",
       " 'Soy',\n",
       " 'Protein Shake',\n",
       " 'Fish',\n",
       " 'Mutton',\n",
       " 'Eggs',\n",
       " 'Mutton',\n",
       " 'Chicken',\n",
       " 'Cheese',\n",
       " 'Beef',\n",
       " 'Mutton',\n",
       " 'Protein Shake',\n",
       " 'Protein Suppliments',\n",
       " 'Soy',\n",
       " 'Cheese',\n",
       " 'Pulses',\n",
       " 'Beef',\n",
       " 'Chicken',\n",
       " 'Mutton',\n",
       " 'Fish',\n",
       " 'Protein Shake',\n",
       " 'Soy',\n",
       " 'Protein Suppliments',\n",
       " 'Pulses',\n",
       " 'Mutton',\n",
       " 'Soy',\n",
       " 'Cheese',\n",
       " 'Chicken',\n",
       " 'Mutton',\n",
       " 'Protein Shake',\n",
       " 'Beef',\n",
       " 'Pulses',\n",
       " 'Protein Suppliments',\n",
       " 'Soy',\n",
       " 'Mutton',\n",
       " 'Eggs',\n",
       " 'Mutton',\n",
       " 'Chicken',\n",
       " 'Protein Shake',\n",
       " 'Pulses',\n",
       " 'Mutton',\n",
       " 'Eggs',\n",
       " 'Protein Suppliments',\n",
       " 'Fish',\n",
       " 'Beef',\n",
       " 'Soy',\n",
       " 'Mutton',\n",
       " 'Chicken',\n",
       " 'Mutton',\n",
       " 'Soy',\n",
       " 'Cheese',\n",
       " 'Beef',\n",
       " 'Protein Suppliments',\n",
       " 'Eggs',\n",
       " 'Mutton']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Make sure you return the Copy of the Final dataframe to this variable**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf= df_updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make sure you run the below files to validate\n",
    "### Do not delete any cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pickle1(file_name, obj):\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pickle.dump(geth(obj), f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pickle2(file_name, obj):\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pickle(file_name):\n",
    "    with open(file_name, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geth(obj):\n",
    "    obj = str(obj).encode()\n",
    "    m = hashlib.md5()\n",
    "    m.update( bytes(obj) )\n",
    "    return m.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickling():\n",
    "    make_pickle1('q1.pickle', q1)\n",
    "    make_pickle1('q2.pickle', q2)\n",
    "    make_pickle1('q3.pickle', q3)\n",
    "    make_pickle1('q4.pickle', q4)\n",
    "    make_pickle1('q5.pickle', q5)\n",
    "    make_pickle1('q6.pickle', q6[159])\n",
    "    make_pickle2('q7.pickle', dataf)\n",
    "\n",
    "    \n",
    "    \n",
    "pickling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Clean_Questions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
